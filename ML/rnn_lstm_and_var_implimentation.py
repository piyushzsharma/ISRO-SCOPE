# -*- coding: utf-8 -*-
"""RNN LSTM and VAR implimentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uswWnNtKTtMOBi7YNLhRNUR9_9D2JeAq
"""

from google.colab import files

uploaded = files.upload()

import pandas as pd
import numpy as np

df = pd.read_csv('DATA_GEO_Train.csv')

df.tail(5)

df['utc_time'].dtype

df['datetime'] = pd.to_datetime(df['utc_time'], format = "%m/%d/%Y %H:%M")

df.sample(5)

df['datetime'].dtype

df['date'] = df['datetime'].dt.date
df['time'] = df['datetime'].dt.time
display(df.head())

df = df.drop(['utc_time', 'datetime'], axis = 1)

df.tail(5)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Combine date and time columns into a single datetime column
df['datetime'] = pd.to_datetime(df['date'].astype(str) + ' ' + df['time'].astype(str))

# Drop original date/time if not needed
df = df.drop(columns=['date', 'time'])

# Sort by datetime and set as index
df = df.sort_values('datetime')
df.set_index('datetime', inplace=True)

# --------------------------
# 2. Handle Missing Values
# --------------------------
df = df.interpolate(method='time')   # interpolate missing numeric values
df = df.fillna(method='bfill').fillna(method='ffill')  # backup fill if start/end missing

# --------------------------
# 3. Compute Derived Metrics
# --------------------------
# Total position error magnitude
df['position_error'] = np.sqrt(df['x_error (m)']**2 + df['y_error (m)']**2 + df['z_error (m)']**2)

# Optional: Rolling average for visualization
df_smooth = df.rolling(window=5, min_periods=1).mean()

# --------------------------
# 4. Visualization
# --------------------------

plt.style.use('seaborn-v0_8-darkgrid')
plt.figure(figsize=(14, 6))
plt.title("Satellite Position Errors Over Time", fontsize=14)
plt.plot(df.index, df['x_error (m)'], label='X Error (m)', alpha=0.7)
plt.plot(df.index, df['y_error (m)'], label='Y Error (m)', alpha=0.7)
plt.plot(df.index, df['z_error (m)'], label='Z Error (m)', alpha=0.7)
plt.plot(df.index, df['position_error'], label='Position Magnitude Error (m)', color='black', linewidth=2)
plt.legend()
plt.xlabel("Time")
plt.ylabel("Error (m)")
plt.tight_layout()
plt.show()

# --------------------------
# 5. Satellite Clock Error Over Time
# --------------------------
plt.figure(figsize=(12,5))
plt.plot(df.index, df['satclockerror (m)'], color='orange', label='Clock Error (m)')
plt.title("Satellite Clock Error Over Time")
plt.xlabel("Time")
plt.ylabel("Clock Error (m)")
plt.legend()
plt.tight_layout()
plt.show()

# --------------------------
# 6. Correlation Heatmap
# --------------------------
plt.figure(figsize=(6,5))
sns.heatmap(df[['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)', 'position_error']].corr(),
            annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Between Error Components")
plt.tight_layout()
plt.show()

# --------------------------
# 7. Distribution Plots
# --------------------------
fig, axes = plt.subplots(2, 2, figsize=(12,8))
sns.histplot(df['x_error (m)'], kde=True, ax=axes[0,0], color='skyblue')
sns.histplot(df['y_error (m)'], kde=True, ax=axes[0,1], color='salmon')
sns.histplot(df['z_error (m)'], kde=True, ax=axes[1,0], color='limegreen')
sns.histplot(df['satclockerror (m)'], kde=True, ax=axes[1,1], color='gold')
axes[0,0].set_title('X Error Distribution')
axes[0,1].set_title('Y Error Distribution')
axes[1,0].set_title('Z Error Distribution')
axes[1,1].set_title('Clock Error Distribution')
plt.tight_layout()
plt.show()

# --------------------------
# 8. Scatter Matrix (Pairplot)
# --------------------------
sns.pairplot(df[['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)', 'position_error']],
             diag_kind='kde')
plt.suptitle("Pairwise Error Relationships", y=1.02)
plt.show()

df.head(5)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# --------------------------
# 2. Handle Missing Values
# --------------------------
df = df.interpolate(method='time')
df = df.fillna(method='bfill').fillna(method='ffill')

# --------------------------
# 3. Derived Metrics
# --------------------------
df['position_error'] = np.sqrt(df['x_error (m)']**2 + df['y_error (m)']**2 + df['z_error (m)']**2)

# --------------------------
# 4. Outlier Detection (3σ Rule)
# --------------------------
def find_outliers(series):
    mean, std = series.mean(), series.std()
    upper, lower = mean + 3*std, mean - 3*std
    return (series > upper) | (series < lower)

outlier_flags = {}
for col in ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)', 'position_error']:
    outlier_flags[col] = find_outliers(df[col])

# --------------------------
# 5. Plot Position Errors (with Outliers)
# --------------------------
plt.style.use('seaborn-v0_8-darkgrid')
plt.figure(figsize=(14, 6))
plt.title("Satellite Position Errors Over Time (Outliers Marked)", fontsize=14)
plt.plot(df.index, df['x_error (m)'], label='X Error (m)', alpha=0.7)
plt.plot(df.index, df['y_error (m)'], label='Y Error (m)', alpha=0.7)
plt.plot(df.index, df['z_error (m)'], label='Z Error (m)', alpha=0.7)
plt.plot(df.index, df['position_error'], label='Position Magnitude Error (m)', color='black', linewidth=2)

# Mark outliers
for col, color in zip(['x_error (m)', 'y_error (m)', 'z_error (m)', 'position_error'],
                      ['blue', 'red', 'green', 'black']):
    plt.scatter(df.index[outlier_flags[col]], df[col][outlier_flags[col]],
                color=color, edgecolor='white', s=60, label=f'{col} Outliers', zorder=5)

plt.legend()
plt.xlabel("Time")
plt.ylabel("Error (m)")
plt.tight_layout()
plt.show()

# --------------------------
# 6. Clock Error with Outliers
# --------------------------
plt.figure(figsize=(12,5))
plt.plot(df.index, df['satclockerror (m)'], color='orange', label='Clock Error (m)')
plt.scatter(df.index[outlier_flags['satclockerror (m)']],
            df['satclockerror (m)'][outlier_flags['satclockerror (m)']],
            color='red', s=50, label='Outliers', zorder=5)
plt.title("Satellite Clock Error Over Time (Outliers Marked)")
plt.xlabel("Time")
plt.ylabel("Clock Error (m)")
plt.legend()
plt.tight_layout()
plt.show()

# --------------------------
# 7. Correlation Heatmap
# --------------------------
plt.figure(figsize=(6,5))
sns.heatmap(df[['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)', 'position_error']].corr(),
            annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Between Error Components")
plt.tight_layout()
plt.show()

# --------------------------
# 8. Distribution Plots
# --------------------------
fig, axes = plt.subplots(2, 2, figsize=(12,8))
sns.histplot(df['x_error (m)'], kde=True, ax=axes[0,0], color='skyblue')
sns.histplot(df['y_error (m)'], kde=True, ax=axes[0,1], color='salmon')
sns.histplot(df['z_error (m)'], kde=True, ax=axes[1,0], color='limegreen')
sns.histplot(df['satclockerror (m)'], kde=True, ax=axes[1,1], color='gold')
axes[0,0].set_title('X Error Distribution')
axes[0,1].set_title('Y Error Distribution')
axes[1,0].set_title('Z Error Distribution')
axes[1,1].set_title('Clock Error Distribution')
plt.tight_layout()
plt.show()

# --------------------------
# 9. Outlier Summary
# --------------------------
outlier_summary = {col: outlier_flags[col].sum() for col in outlier_flags}
print("Outlier Counts per Column:")
for k, v in outlier_summary.items():
    print(f"  {k:25s}: {v} outliers")

spearman_corr = df[['x_error (m)', 'y_error (m)', 'z_error (m)',
                    'satclockerror (m)', 'position_error']].corr(method='spearman')
print(spearman_corr)

from statsmodels.tsa.api import VAR

var_model = VAR(df[['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']])
results = var_model.fit(maxlags=2)
print(results.summary())

import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(6,6))
plt.scatter(df['x_error (m)'], df['position_error'], alpha=0.5, label='X vs Total')
plt.scatter(df['y_error (m)'], df['position_error'], alpha=0.5, label='Y vs Total')
plt.scatter(df['z_error (m)'], df['position_error'], alpha=0.5, label='Z vs Total')
plt.xlabel("Individual Coordinate Error (m)")
plt.ylabel("Total Position Error (m)")
plt.legend()
plt.title("Nonlinear Relationship between Axis Errors and Total Position Error")
plt.show()

df.head(5)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from statsmodels.tsa.api import VAR

# --- Load and preprocess ---
# Access the index directly to get the day
df['day'] = df.index.day

# --- Create derived features ---
df['xy_sum'] = df['x_error (m)'] * df['y_error (m)']
df['yz_sum'] = df['y_error (m)'] * df['z_error (m)']
df['zx_sum'] = df['z_error (m)'] * df['x_error (m)']

# Feature selection
features = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)', 'xy_sum', 'yz_sum', 'zx_sum']

# Scale robustly (keeps outliers)
scaler = RobustScaler()
df_scaled = df.copy()
df_scaled[features] = scaler.fit_transform(df[features])

# Split train (1–6) and test (7)
train = df_scaled[df_scaled['day'] <= 6][features]
test = df_scaled[df_scaled['day'] > 6][features]

# --- Train VAR ---
model = VAR(train)
results = model.fit(maxlags=5, ic='aic') # Reduced maxlags
# print(f"Optimal lag order selected by AIC: {results.k_ar}")
print(results.summary())

# --- Forecast Day 7 ---
lag_order = results.k_ar
forecast_input = train.values[-lag_order:]
forecast = results.forecast(y=forecast_input, steps=len(test))
forecast_df = pd.DataFrame(forecast, columns=features, index=test.index)

# --- Plot ---
# --- Plot Results on Separate Subplots ---
# Create a figure with one subplot for each feature
fig, axes = plt.subplots(nrows=len(features), ncols=1, figsize=(12, 10), sharex=True)

for i, col in enumerate(features):
    # Plot Actual values for the current feature
    axes[i].plot(test[col], label=f'Actual {col}')

    # Plot Predicted values for the current feature
    axes[i].plot(forecast_df[col], linestyle='--', label=f'Predicted {col}')

    # Set titles and labels for clarity
    axes[i].set_ylabel("Scaled Error")
    axes[i].set_title(f'Forecast vs Actual for {col}')
    axes[i].legend()
    axes[i].grid(True)

# Add a shared x-label and a main title
plt.xlabel("Time")
fig.suptitle("VAR Model Forecast vs Actuals (Day 7)", fontsize=16)
plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for the suptitle
plt.show()

# --- Outlier Marking (Z-score based on train stats) ---
from scipy.stats import zscore
z_scores = np.abs(zscore(df_scaled[features]))
outlier_mask = (z_scores > 2).any(axis=1)
plt.figure(figsize=(10,5))
# Use df_scaled.index for plotting
plt.scatter(df_scaled.index, df_scaled['x_error (m)'], c=outlier_mask, cmap='coolwarm', s=40)
plt.title("Outlier points (colored red)")
plt.xlabel("Time")
plt.ylabel("x_error (scaled)")
plt.show()

df.sample(5)

import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# --- Load and preprocess ---
df['day'] = df.index.day

features = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']

# Robust scaling to preserve outliers
scaler = RobustScaler()
df[features] = scaler.fit_transform(df[features])

# --- Split data ---
# Include all of day 6 and day 7 in the test set
train_df = df[df['day'] <= 5][features].values
test_df = df[df['day'] >= 6][features].values # Changed to include day 6 and 7

# --- Create time sequences ---
def create_sequences(data, seq_len=5):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

seq_len = 5
X_train, y_train = create_sequences(train_df, seq_len)
X_test, y_test = create_sequences(test_df, seq_len)


# --- Build LSTM model ---
model = Sequential([
    LSTM(128, activation='relu', return_sequences=True, input_shape=(seq_len, len(features))),
    Dropout(0.3),
    LSTM(64, activation='tanh'),
    Dense(len(features))
])

model.compile(optimizer='adam', loss='mse')
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# --- Train ---
history = model.fit(
    X_train, y_train,
    epochs=10,
    batch_size=8,
    validation_split=0.2,
    callbacks=[early_stop],
    verbose=1
)

# --- Evaluate & Predict ---
preds = model.predict(X_test)

# --- Plot 1: Training vs Validation loss ---
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss', linestyle='--')
plt.title("Training vs Validation Loss (LSTM)")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.legend()
plt.grid(True)
plt.show()

# --- Predict for test data ---
y_pred = model.predict(X_test)

# --- Plot actual vs predicted ---
plt.figure(figsize=(10,5))
plt.plot(y_test, label='Actual', color='blue')
plt.plot(y_pred, label='Predicted', color='orange', linestyle='--')
plt.title('LSTM Predictions for Days 6–7')
plt.xlabel('Time Step')
plt.ylabel('Error Value')
plt.legend()
plt.grid(True)
plt.show()

# For multi-output prediction
plt.figure(figsize=(12,8)) # Adjusted figure size for 4 subplots
for i, col in enumerate(features):  # e.g. ['x_error','y_error','z_error']
    plt.subplot(4,1,i+1) # Changed to 4 rows, 1 column
    plt.plot(y_test[:, i], label=f'Actual {col}')
    plt.plot(y_pred[:, i], '--', label=f'Predicted {col}')
    plt.ylabel(col) # Label the y-axis with the feature name
    plt.legend()
    plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, MultiHeadAttention, LayerNormalization, Dropout, Dense, GlobalAveragePooling1D, Layer
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

# --- Custom Positional Encoding Layer ---
class PositionalEncoding(Layer):
    def __init__(self, position, d_model):
        super(PositionalEncoding, self).__init__()
        self.pos_encoding = self.positional_encoding(position, d_model)

    def get_angles(self, position, i, d_model):
        angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
        return position * angles

    def positional_encoding(self, position, d_model):
        angle_rads = self.get_angles(
            np.arange(position)[:, np.newaxis],
            np.arange(d_model)[np.newaxis, :],
            d_model
        )
        # apply sin to even indices in the array; 2i
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        # apply cos to odd indices in the array; 2i+1
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        pos_encoding = angle_rads[np.newaxis, ...]
        return tf.cast(pos_encoding, dtype=tf.float32)

    def call(self, inputs):
        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]

# --- 1. Load and Preprocess Data ---

# Create dummy data with a more pronounced cyclical pattern for better demonstration
df['day'] = df.index.day

features = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']
num_features = len(features)

scaler = RobustScaler()
df_scaled = df.copy()
df_scaled[features] = scaler.fit_transform(df[features])

# --- 2. Split and Create Sequences ---

train_df = df_scaled[df_scaled['day'] <= 5][features].values
test_df = df_scaled[df_scaled['day'] >= 6][features].values

def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i + seq_len])
        y.append(data[i + seq_len])
    return np.array(X), np.array(y)

seq_len = 30 # Sequence length
X_train, y_train = create_sequences(train_df, seq_len)
X_test, y_test = create_sequences(test_df, seq_len)

# --- 3. Build the Transformer Model ---

def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_blocks, dropout_rate):
    inputs = Input(shape=input_shape)

    # Project input to a higher dimension
    x = Dense(head_size * num_heads)(inputs)

    # Add positional encoding
    x = PositionalEncoding(input_shape[0], head_size * num_heads)(x)

    for _ in range(num_blocks):
        attention_output = MultiHeadAttention(
            key_dim=head_size, num_heads=num_heads, dropout=dropout_rate
        )(x, x)
        x = LayerNormalization(epsilon=1e-6)(x + attention_output)

        ffn_output = Dense(ff_dim, activation="relu")(x)
        ffn_output = Dense(head_size * num_heads)(ffn_output)
        ffn_output = Dropout(dropout_rate)(ffn_output)
        x = LayerNormalization(epsilon=1e-6)(x + ffn_output)

    x = GlobalAveragePooling1D(data_format="channels_last")(x)
    outputs = Dense(num_features)(x)

    return Model(inputs, outputs)

# Model hyperparameters
HEAD_SIZE = 64
NUM_HEADS = 4
FF_DIM = 64
NUM_BLOCKS = 2
DROPOUT_RATE = 0.1

model = build_transformer_model(
    input_shape=(seq_len, num_features),
    head_size=HEAD_SIZE,
    num_heads=NUM_HEADS,
    ff_dim=FF_DIM,
    num_blocks=NUM_BLOCKS,
    dropout_rate=DROPOUT_RATE,
)

model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss='mse')
model.summary()

early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)

# --- 4. Train and Evaluate ---
history = model.fit(
    X_train, y_train,
    epochs=100,
    batch_size=8, # Increased batch size for stability
    validation_split=0.2,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

# Plotting loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title("Transformer Model Loss")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.legend()
plt.grid(True)
plt.show()

# --- 5. Predict and Plot ---
y_pred_scaled = model.predict(X_test)
y_pred = scaler.inverse_transform(y_pred_scaled)
y_test_actual = scaler.inverse_transform(y_test)

plt.figure(figsize=(15, 10))
for i, col in enumerate(features):
    plt.subplot(num_features, 1, i + 1)
    plt.plot(y_test_actual[:, i], label=f'Actual {col}', color='blue')
    plt.plot(y_pred[:, i], label=f'Predicted {col}', color='orange', linestyle='--')
    plt.title(f'Actual vs. Predicted - {col}')
    plt.ylabel('Error (m)')
    plt.legend()
    plt.grid(True)

plt.xlabel('Time Step')
plt.tight_layout()
plt.show()

df.head()

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import SimpleRNN, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# # --- Create derived features ---
# df['xy_sum'] = df['x_error (m)'] + df['y_error (m)']
# df['yz_sum'] = df['y_error (m)'] + df['z_error (m)']
# df['zx_sum'] = df['z_error (m)'] + df['x_error (m)']

# --- Define input & output features ---
input_features = [
    'x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)',
    'xy_sum', 'yz_sum', 'zx_sum'
]
output_features = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']

# --- Scaling ---
scaler = RobustScaler()
df[input_features] = scaler.fit_transform(df[input_features])

# --- Split ---
train_df = df[df['day'] <= 5]
test_df = df[df['day'] >= 6]

def create_sequences(data, seq_len=5):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[input_features].iloc[i:i+seq_len].values)
        y.append(data[output_features].iloc[i+seq_len].values)
    return np.array(X), np.array(y)

seq_len = 5
X_train, y_train = create_sequences(train_df)
X_test, y_test = create_sequences(test_df)

# --- RNN model ---
model = Sequential([
    SimpleRNN(128, activation='relu', return_sequences=True, input_shape=(seq_len, len(input_features))),
    Dropout(0.3),
    SimpleRNN(64, activation='tanh'),
    Dense(len(output_features))
])

model.compile(optimizer='adam', loss='mse')
early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)

# --- Train ---
history = model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=8,
    validation_split=0.2,
    callbacks=[early_stop],
    verbose=1
)

# --- Predict ---
y_pred_rnn = model.predict(X_test)

# --- Plot validation ---
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], '--', label='Val Loss')
plt.title("RNN Training vs Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE")
plt.legend()
plt.grid(True)
plt.show()

# --- Plot results ---
features = output_features
plt.figure(figsize=(12,8))
for i, col in enumerate(features):
    plt.subplot(len(features), 1, i+1)
    plt.plot(y_test[:, i], label=f'Actual {col}')
    plt.plot(y_pred_rnn[:, i], '--', label=f'Predicted {col}')
    plt.ylabel(col)
    plt.legend()
    plt.grid(True)
plt.tight_layout()
plt.show()

from scipy import stats
import numpy as np
import matplotlib.pyplot as plt

# --- Compute prediction errors ---
errors = y_test - y_pred_rnn  # shape: (samples, 4)

# --- Plot error distribution for each output ---
for i, col in enumerate(output_features):
    plt.figure(figsize=(6,4))
    plt.hist(errors[:, i], bins=30, density=True, alpha=0.6, color='skyblue')

    # Fit a normal distribution
    mu, std = np.mean(errors[:, i]), np.std(errors[:, i])
    xmin, xmax = plt.xlim()
    x = np.linspace(xmin, xmax, 100)
    p = stats.norm.pdf(x, mu, std)
    plt.plot(x, p, 'r', linewidth=2, label='Normal Fit')

    plt.title(f'Error Distribution for {col}\nμ={mu:.3f}, σ={std:.3f}')
    plt.legend()
    plt.grid(True)
    plt.show()

# --- Normality test (e.g., Shapiro-Wilk or Kolmogorov–Smirnov) ---
for i, col in enumerate(output_features):
    stat, p_value = stats.shapiro(errors[:, i])
    print(f"{col} → Shapiro-Wilk Test: Statistic={stat:.3f}, p-value={p_value:.4f}")
    if p_value > 0.05:
        print("Likely normal distribution\n")
    else:
        print(" Deviates from normal distribution\n")

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import RobustScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

# --- Create derived features ---
# df['xy_sum'] = df['x_error (m)'] + df['y_error (m)']
# df['yz_sum'] = df['y_error (m)'] + df['z_error (m)']
# df['zx_sum'] = df['z_error (m)'] + df['x_error (m)']

# --- Define input & output features ---
input_features = [
    'x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)'
]
output_features = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']

# --- Scaling ---
scaler = RobustScaler()
df[input_features] = scaler.fit_transform(df[input_features])

# --- Split ---
train_df = df[df['day'] <= 5]
test_df = df[df['day'] >= 6]

def create_sequences(data, seq_len=5):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[input_features].iloc[i:i+seq_len].values)
        y.append(data[output_features].iloc[i+seq_len].values)
    return np.array(X), np.array(y)

seq_len = 5
X_train, y_train = create_sequences(train_df)
X_test, y_test = create_sequences(test_df)

# --- LSTM model ---
model = Sequential([
    LSTM(128, activation='relu', return_sequences=True, input_shape=(seq_len, len(input_features))),
    Dropout(0.3),
    LSTM(64, activation='tanh'),
    Dense(len(output_features))
])

model.compile(optimizer='adam', loss='mse')
early_stop = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)

# --- Train ---
history = model.fit(
    X_train, y_train,
    epochs=20,
    batch_size=4,
    validation_split=0.2,
    callbacks=[early_stop],
    verbose=1
)

# --- Predict ---
y_pred_lstm = model.predict(X_test)

# --- Plot validation ---
plt.figure(figsize=(8,5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], '--', label='Val Loss')
plt.title("LSTM Training vs Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("MSE")
plt.legend()
plt.grid(True)
plt.show()

# --- Plot results ---
features = output_features
plt.figure(figsize=(12,8))
for i, col in enumerate(features):
    plt.subplot(len(features), 1, i+1)
    plt.plot(y_test[:, i], label=f'Actual {col}')
    plt.plot(y_pred_lstm[:, i], '--', label=f'Predicted {col}')
    plt.ylabel(col)
    plt.legend()
    plt.grid(True)
plt.tight_layout()
plt.show()

from scipy import stats
import numpy as np
import matplotlib.pyplot as plt

# --- Compute prediction errors ---
errors = y_test - y_pred_lstm  # shape: (samples, 4)

# --- Plot error distribution for each output ---
for i, col in enumerate(output_features):
    plt.figure(figsize=(6,4))
    plt.hist(errors[:, i], bins=30, density=True, alpha=0.6, color='skyblue')

    # Fit a normal distribution
    mu, std = np.mean(errors[:, i]), np.std(errors[:, i])
    xmin, xmax = plt.xlim()
    x = np.linspace(xmin, xmax, 100)
    p = stats.norm.pdf(x, mu, std)
    plt.plot(x, p, 'r', linewidth=2, label='Normal Fit')

    plt.title(f'Error Distribution for {col}\nμ={mu:.3f}, σ={std:.3f}')
    plt.legend()
    plt.grid(True)
    plt.show()

# --- Normality test (e.g., Shapiro-Wilk or Kolmogorov–Smirnov) ---
for i, col in enumerate(output_features):
    stat, p_value = stats.shapiro(errors[:, i])
    print(f"{col} → Shapiro-Wilk Test: Statistic={stat:.3f}, p-value={p_value:.4f}")
    if p_value > 0.05:
        print("✅ Likely normal distribution\n")
    else:
        print("⚠️ Deviates from normal distribution\n")



# GAN for synthesizing error sequences (LSTM-based generator & discriminator)

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, losses
from sklearn.preprocessing import RobustScaler
import matplotlib.pyplot as plt

# --- Settings ---
seq_len = 10                  # length of sequence to synthesize
n_features = 4                # x,y,z,satclockerror
latent_dim = 64               # noise vector size
batch_size = 64
epochs = 3000                 # adjust (higher -> better quality)
print_every = 250

# --- Prepare sequence data (use only error columns) ---
error_cols = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']
# Optionally filter training days like before
train_df = df[df['day'] <= 5].copy()
errors = train_df[error_cols].values

# scale errors
scaler = RobustScaler()
errors_scaled = scaler.fit_transform(errors)

def create_sequences_arr(arr, seq_len):
    X = []
    for i in range(len(arr) - seq_len):
        X.append(arr[i:i+seq_len])
    return np.array(X)

X_seq = create_sequences_arr(errors_scaled, seq_len)  # shape: (samples, seq_len, n_features)
print("GAN training sequences shape:", X_seq.shape)

# Create tf.data.Dataset
dataset = (tf.data.Dataset.from_tensor_slices(X_seq)
           .shuffle(buffer_size=2048)
           .batch(batch_size, drop_remainder=True)
           .prefetch(tf.data.AUTOTUNE))

# --- Build Generator: noise -> sequence (seq_len, n_features) ---
def build_generator(seq_len, n_features, latent_dim):
    model = models.Sequential([
        layers.Input(shape=(latent_dim,)),
        layers.Dense(seq_len * 128, activation='relu'),
        layers.Reshape((seq_len, 128)),
        layers.LSTM(128, return_sequences=True),
        layers.TimeDistributed(layers.Dense(64, activation='relu')),
        layers.TimeDistributed(layers.Dense(n_features, activation='linear'))  # output scaled values
    ], name="generator")
    return model

# --- Build Discriminator: sequence -> probability ---
def build_discriminator(seq_len, n_features):
    inp = layers.Input(shape=(seq_len, n_features))
    x = layers.LSTM(128, return_sequences=False)(inp)
    x = layers.Dense(64, activation='relu')(x)
    out = layers.Dense(1, activation='sigmoid')(x)
    model = models.Model(inp, out, name="discriminator")
    return model

generator = build_generator(seq_len, n_features, latent_dim)
discriminator = build_discriminator(seq_len, n_features)

# Optimizers & loss
opt_gen = optimizers.Adam(learning_rate=2e-4, beta_1=0.5)
opt_disc = optimizers.Adam(learning_rate=2e-4, beta_1=0.5)
bce = losses.BinaryCrossentropy(from_logits=False)

# For training tracking
g_losses, d_losses = [], []

# --- Training loop (vanilla GAN) ---
@tf.function
def train_step(real_sequences):
    batch_size = tf.shape(real_sequences)[0]
    # Create real & fake labels (with label smoothing for stability)
    real_labels = tf.ones((batch_size, 1)) * 0.9
    fake_labels = tf.zeros((batch_size, 1))

    # 1) Train discriminator on real + fake
    noise = tf.random.normal((batch_size, latent_dim))
    fake_sequences = generator(noise, training=True)

    with tf.GradientTape() as tape_d:
        real_out = discriminator(real_sequences, training=True)
        fake_out = discriminator(fake_sequences, training=True)
        d_loss_real = bce(real_labels, real_out)
        d_loss_fake = bce(fake_labels, fake_out)
        d_loss = 0.5 * (d_loss_real + d_loss_fake)
    grads_d = tape_d.gradient(d_loss, discriminator.trainable_variables)
    opt_disc.apply_gradients(zip(grads_d, discriminator.trainable_variables))

    # 2) Train generator (via discriminator feedback)
    noise2 = tf.random.normal((batch_size, latent_dim))
    misleading_labels = tf.ones((batch_size, 1))  # want discriminator to think fakes are real
    with tf.GradientTape() as tape_g:
        gen_seq = generator(noise2, training=True)
        pred = discriminator(gen_seq, training=True)
        g_loss = bce(misleading_labels, pred)
    grads_g = tape_g.gradient(g_loss, generator.trainable_variables)
    opt_gen.apply_gradients(zip(grads_g, generator.trainable_variables))

    return d_loss, g_loss

# Training
for epoch in range(1, epochs + 1):
    d_epoch = []
    g_epoch = []
    for real_batch in dataset:
        d_loss_batch, g_loss_batch = train_step(real_batch)
        d_epoch.append(d_loss_batch.numpy())
        g_epoch.append(g_loss_batch.numpy())
    d_mean = np.mean(d_epoch)
    g_mean = np.mean(g_epoch)
    d_losses.append(d_mean)
    g_losses.append(g_mean)

    if epoch % print_every == 0 or epoch == 1:
        print(f"Epoch {epoch}/{epochs}  D_loss={d_mean:.4f}  G_loss={g_mean:.4f}")

# --- Generate samples after training ---
def sample_generator(n_samples=10):
    z = np.random.normal(size=(n_samples, latent_dim))
    gen = generator.predict(z)                # shape: (n_samples, seq_len, n_features)
    # flatten and inverse scale for inspection (we inverse transform each time step)
    gen_reshaped = gen.reshape(-1, n_features)
    gen_inv = scaler.inverse_transform(gen_reshaped).reshape(n_samples, seq_len, n_features)
    return gen_inv

# Example: generate 5 sequences and plot first feature (x_error) sample
gen_seqs = sample_generator(5)
print("Generated sequences shape (in original scale):", gen_seqs.shape)

# quick plot: compare distributions of generated vs real on each feature (flattened across time)
real_flat = X_seq.reshape(-1, n_features)
real_inv = scaler.inverse_transform(real_flat)

gen_flat = gen_seqs.reshape(-1, n_features)

plt.figure(figsize=(10,6))
for i, col in enumerate(error_cols):
    plt.subplot(2,2,i+1)
    plt.hist(real_inv[:, i], bins=40, density=True, alpha=0.5, label='real')
    plt.hist(gen_flat[:, i], bins=40, density=True, alpha=0.5, label='gen')
    plt.title(col)
    plt.legend()
plt.tight_layout()
plt.show()

# Save generator for later use
generator.save("lstm_sequence_generator.h5")
print("Generator saved to lstm_sequence_generator.h5")



# WGAN-GP for synthesizing GNSS error sequences (LSTM-based)
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import RobustScaler
import matplotlib.pyplot as plt

# ---------- User parameters ----------
seq_len = 10                # sequence length to model
n_features = 4              # x,y,z,satclockerror
latent_dim = 64
batch_size = 16             # small dataset -> small batch
critic_steps = 5            # number of critic updates per generator update
gp_weight = 10.0            # gradient penalty weight (lambda)
epochs = 1500             # adjust as needed (increase if training stable)
learning_rate = 1e-3
# -------------------------------------

# --- Prepare training sequences (days 1-5) ---
error_cols = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']
train_df = df[df['day'] <= 5].copy()
errors = train_df[error_cols].values

# scale errors
scaler = RobustScaler()
errors_scaled = scaler.fit_transform(errors)

def create_sequences_arr(arr, seq_len):
    X = []
    for i in range(len(arr) - seq_len):
        X.append(arr[i:i+seq_len])
    return np.array(X)

X_seq = create_sequences_arr(errors_scaled, seq_len)  # (samples, seq_len, n_features)
print("Sequences shape:", X_seq.shape)

dataset = (tf.data.Dataset.from_tensor_slices(X_seq.astype(np.float32)) # Ensure float32
           .shuffle(buffer_size=2048)
           .batch(batch_size, drop_remainder=True)
           .prefetch(tf.data.AUTOTUNE))

# --- Model builders ---
def build_generator(seq_len, n_features, latent_dim):
    inp = layers.Input(shape=(latent_dim,))
    x = layers.Dense(seq_len * 128, activation='relu')(inp)
    x = layers.Reshape((seq_len, 128))(x)
    x = layers.LSTM(128, return_sequences=True)(x)
    x = layers.TimeDistributed(layers.Dense(64, activation='relu'))(x)
    out = layers.TimeDistributed(layers.Dense(n_features, activation='linear'))(x)
    return models.Model(inp, out, name='Generator')

def build_critic(seq_len, n_features):
    inp = layers.Input(shape=(seq_len, n_features))
    x = layers.LSTM(128, return_sequences=False)(inp)
    x = layers.Dense(64, activation='relu')(x)
    out = layers.Dense(1, activation='linear')(x)  # WGAN critic outputs real-valued score
    return models.Model(inp, out, name='Critic')

generator = build_generator(seq_len, n_features, latent_dim)
critic = build_critic(seq_len, n_features)

# --- Optimizers ---
g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.0, beta_2=0.9)
c_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.0, beta_2=0.9)

# --- Helper: gradient penalty ---
def gradient_penalty(critic, real, fake):
    # real, fake: shape (batch, seq_len, n_features)
    alpha = tf.random.uniform([real.shape[0], 1, 1], 0.0, 1.0)
    diff = fake - real
    interpolated = real + alpha * diff
    with tf.GradientTape() as gp_tape:
        gp_tape.watch(interpolated)
        pred = critic(interpolated, training=True)
    grads = gp_tape.gradient(pred, [interpolated])[0]  # shape same as interpolated
    grads = tf.reshape(grads, (grads.shape[0], -1))
    gp = tf.reduce_mean((tf.norm(grads, axis=1) - 1.0) ** 2)
    return gp

# --- Losses for WGAN ---
def critic_loss(real_output, fake_output, gp, gp_weight):
    # WGAN critic: E[fake] - E[real] + lambda * GP
    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output) + gp_weight * gp

def generator_loss(fake_output):
    # WGAN generator: -E[fake_scores]
    return -tf.reduce_mean(fake_output)

# --- Training step ---
@tf.function
def train_critic_step(real_sequences):
    batch_size_tf = tf.shape(real_sequences)[0]
    c_loss = tf.constant(0.0, dtype=tf.float32) # Initialize c_loss
    for _ in tf.range(critic_steps):  # Use the defined critic_steps
        noise = tf.random.normal((batch_size_tf, latent_dim), dtype=tf.float32) # Ensure float32
        with tf.GradientTape() as tape_c:
            fake_sequences = generator(noise, training=True)
            real_out = critic(real_sequences, training=True)
            fake_out = critic(fake_sequences, training=True)
            gp = gradient_penalty(critic, real_sequences, fake_sequences)
            c_loss = critic_loss(real_out, fake_out, gp, gp_weight)
        grads = tape_c.gradient(c_loss, critic.trainable_variables)
        c_optimizer.apply_gradients(zip(grads, critic.trainable_variables))
    return c_loss

@tf.function
def train_generator_step(batch_size_tf):
    noise = tf.random.normal((batch_size_tf, latent_dim), dtype=tf.float32) # Ensure float32
    with tf.GradientTape() as tape_g:
        fake_sequences = generator(noise, training=True)
        fake_out = critic(fake_sequences, training=True)
        g_loss = generator_loss(fake_out)
    grads_g = tape_g.gradient(g_loss, generator.trainable_variables)
    g_optimizer.apply_gradients(zip(grads_g, generator.trainable_variables))
    return g_loss

# --- Training loop ---
g_losses = []
c_losses = []
step = 0
for epoch in range(1, epochs + 1):
    c_epoch_losses = []
    g_epoch_losses = []
    for real_batch in dataset:
        # update critic multiple times

        c_loss = train_critic_step(real_batch)
        # update generator once
        g_loss = train_generator_step(batch_size)
        c_epoch_losses.append(c_loss.numpy())
        g_epoch_losses.append(g_loss.numpy())
        step += 1

    c_losses.append(np.mean(c_epoch_losses))
    g_losses.append(np.mean(g_epoch_losses))

    if epoch % 50 == 0 or epoch == 1:
        print(f"Epoch {epoch}/{epochs}  Critic_loss={c_losses[-1]:.4f}  Gen_loss={g_losses[-1]:.4f}")

# --- Generate samples after training ---
def sample_generator(n_samples=20):
    z = np.random.normal(size=(n_samples, latent_dim)).astype(np.float32) # Ensure float32
    gen = generator.predict(z)  # shape: (n_samples, seq_len, n_features) scaled space
    gen_flat = gen.reshape(-1, n_features)
    gen_inv = scaler.inverse_transform(gen_flat).reshape(n_samples, seq_len, n_features)
    return gen_inv

gen_seqs = sample_generator(10)  # 10 generated sequences
print("Generated sequences shape (orig scale):", gen_seqs.shape)

# --- Quick distribution comparison (flattened across time) ---
real_flat = X_seq.reshape(-1, n_features)
real_inv = scaler.inverse_transform(real_flat)
gen_flat = gen_seqs.reshape(-1, n_features)

plt.figure(figsize=(10,6))
for i, col in enumerate(error_cols):
    plt.subplot(2,2,i+1)
    plt.hist(real_inv[:, i], bins=40, density=True, alpha=0.5, label='real')
    plt.hist(gen_flat[:, i], bins=40, density=True, alpha=0.5, label='gen')
    plt.title(col)
    plt.legend()
plt.tight_layout()
plt.show()

# Save generator and critic
generator.save("wgan_gp_generator.h5")
critic.save("wgan_gp_critic.h5")
print("Saved generator and critic models.")

# WGAN-GP for synthesizing GNSS error sequences (LSTM-based)
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import RobustScaler
import matplotlib.pyplot as plt

# ---------- User parameters ----------
seq_len = 10                # sequence length to model
n_features = 4              # x,y,z,satclockerror
latent_dim = 64
batch_size = 16             # small dataset -> small batch
critic_steps = 5            # number of critic updates per generator update
gp_weight = 10.0            # gradient penalty weight (lambda)
epochs = 1500             # adjust as needed (increase if training stable)
learning_rate = 1e-3
# -------------------------------------

# --- Prepare training sequences (days 1-5) ---
error_cols = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']
train_df = df[df['day'] <= 5].copy()
errors = train_df[error_cols].values

# scale errors
scaler = RobustScaler()
errors_scaled = scaler.fit_transform(errors)

def create_sequences_arr(arr, seq_len):
    X = []
    for i in range(len(arr) - seq_len):
        X.append(arr[i:i+seq_len])
    return np.array(X)

X_seq = create_sequences_arr(errors_scaled, seq_len)  # (samples, seq_len, n_features)
print("Sequences shape:", X_seq.shape)

dataset = (tf.data.Dataset.from_tensor_slices(X_seq.astype(np.float32)) # Ensure float32
           .shuffle(buffer_size=2048)
           .batch(batch_size, drop_remainder=True)
           .prefetch(tf.data.AUTOTUNE))

# --- Model builders ---
def build_generator(seq_len, n_features, latent_dim):
    inp = layers.Input(shape=(latent_dim,))
    x = layers.Dense(seq_len * 128, activation='relu')(inp)
    x = layers.Reshape((seq_len, 128))(x)
    x = layers.LSTM(128, return_sequences=True)(x)
    x = layers.TimeDistributed(layers.Dense(64, activation='relu'))(x)
    out = layers.TimeDistributed(layers.Dense(n_features, activation='linear'))(x)
    return models.Model(inp, out, name='Generator')

def build_critic(seq_len, n_features):
    inp = layers.Input(shape=(seq_len, n_features))
    x = layers.LSTM(128, return_sequences=False)(inp)
    x = layers.Dense(64, activation='relu')(x)
    out = layers.Dense(1, activation='linear')(x)  # WGAN critic outputs real-valued score
    return models.Model(inp, out, name='Critic')

generator = build_generator(seq_len, n_features, latent_dim)
critic = build_critic(seq_len, n_features)

# --- Optimizers ---
g_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.0, beta_2=0.9)
c_optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1=0.0, beta_2=0.9)

# --- Helper: gradient penalty ---
def gradient_penalty(critic, real, fake):
    # real, fake: shape (batch, seq_len, n_features)
    alpha = tf.random.uniform([real.shape[0], 1, 1], 0.0, 1.0)
    diff = fake - real
    interpolated = real + alpha * diff
    with tf.GradientTape() as gp_tape:
        gp_tape.watch(interpolated)
        pred = critic(interpolated, training=True)
    grads = gp_tape.gradient(pred, [interpolated])[0]  # shape same as interpolated
    grads = tf.reshape(grads, (grads.shape[0], -1))
    gp = tf.reduce_mean((tf.norm(grads, axis=1) - 1.0) ** 2)
    return gp

# --- Losses for WGAN ---
def critic_loss(real_output, fake_output, gp, gp_weight):
    # WGAN critic: E[fake] - E[real] + lambda * GP
    return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output) + gp_weight * gp

def generator_loss(fake_output):
    # WGAN generator: -E[fake_scores]
    return -tf.reduce_mean(fake_output)

# --- Training step ---
@tf.function
def train_critic_step(real_sequences):
    batch_size_tf = tf.shape(real_sequences)[0]
    c_loss = tf.constant(0.0, dtype=tf.float32) # Initialize c_loss
    for _ in tf.range(critic_steps):  # Use the defined critic_steps
        noise = tf.random.normal((batch_size_tf, latent_dim), dtype=tf.float32) # Ensure float32
        with tf.GradientTape() as tape_c:
            fake_sequences = generator(noise, training=True)
            real_out = critic(real_sequences, training=True)
            fake_out = critic(fake_sequences, training=True)
            gp = gradient_penalty(critic, real_sequences, fake_sequences)
            c_loss = critic_loss(real_out, fake_out, gp, gp_weight)
        grads = tape_c.gradient(c_loss, critic.trainable_variables)
        c_optimizer.apply_gradients(zip(grads, critic.trainable_variables))
    return c_loss

@tf.function
def train_generator_step(batch_size_tf):
    noise = tf.random.normal((batch_size_tf, latent_dim), dtype=tf.float32) # Ensure float32
    with tf.GradientTape() as tape_g:
        fake_sequences = generator(noise, training=True)
        fake_out = critic(fake_sequences, training=True)
        g_loss = generator_loss(fake_out)
    grads_g = tape_g.gradient(g_loss, generator.trainable_variables)
    g_optimizer.apply_gradients(zip(grads_g, generator.trainable_variables))
    return g_loss

# --- Training loop ---
g_losses = []
c_losses = []
step = 0
for epoch in range(1, epochs + 1):
    c_epoch_losses = []
    g_epoch_losses = []
    for real_batch in dataset:
        # update critic multiple times

        c_loss = train_critic_step(real_batch)
        # update generator once
        g_loss = train_generator_step(batch_size)
        c_epoch_losses.append(c_loss.numpy())
        g_epoch_losses.append(g_loss.numpy())
        step += 1

    c_losses.append(np.mean(c_epoch_losses))
    g_losses.append(np.mean(g_epoch_losses))

    if epoch % 50 == 0 or epoch == 1:
        print(f"Epoch {epoch}/{epochs}  Critic_loss={c_losses[-1]:.4f}  Gen_loss={g_losses[-1]:.4f}")

# --- Generate samples after training ---
def sample_generator(n_samples=20):
    z = np.random.normal(size=(n_samples, latent_dim)).astype(np.float32) # Ensure float32
    gen = generator.predict(z)  # shape: (n_samples, seq_len, n_features) scaled space
    gen_flat = gen.reshape(-1, n_features)
    gen_inv = scaler.inverse_transform(gen_flat).reshape(n_samples, seq_len, n_features)
    return gen_inv

gen_seqs = sample_generator(10)  # 10 generated sequences
print("Generated sequences shape (orig scale):", gen_seqs.shape)

# --- Quick distribution comparison (flattened across time) ---
real_flat = X_seq.reshape(-1, n_features)
real_inv = scaler.inverse_transform(real_flat)
gen_flat = gen_seqs.reshape(-1, n_features)

plt.figure(figsize=(10,6))
for i, col in enumerate(error_cols):
    plt.subplot(2,2,i+1)
    plt.hist(real_inv[:, i], bins=40, density=True, alpha=0.5, label='real')
    plt.hist(gen_flat[:, i], bins=40, density=True, alpha=0.5, label='gen')
    plt.title(col)
    plt.legend()
plt.tight_layout()
plt.show()

# Save generator and critic
generator.save("wgan_gp_generator.h5")
critic.save("wgan_gp_critic.h5")
print("Saved generator and critic models.")



df.head(5)

