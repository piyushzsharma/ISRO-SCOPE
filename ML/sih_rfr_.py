# -*- coding: utf-8 -*-
"""SIH - RFR .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X9W5sQugqHDQDIvCbuULd2wRndalSg5q
"""

import pandas as pd

df = pd.read_csv('DATA_GEO_Train.csv')

df.head()

df['utc_time'].dtype

import pandas as pd
from sklearn.ensemble import RandomForestRegressor
import numpy as np
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('DATA_GEO_Train.csv')

# Convert 'utc_time' to datetime and set it as the index
df['utc_time'] = pd.to_datetime(df['utc_time'])
df = df.set_index('utc_time')

# Create time-based features
df['day_of_year'] = df.index.dayofyear
df['day_of_month'] = df.index.day
df['day_of_week'] = df.index.dayofweek
df['hour'] = df.index.hour
df['minute'] = df.index.minute

# Define features and targets
features = ['day_of_year', 'day_of_month', 'day_of_week', 'hour', 'minute']
targets = ['x_error (m)', 'y_error (m)', 'z_error (m)', 'satclockerror (m)']

X = df[features]
y = df[targets]

# Train a RandomForestRegressor for each target variable
models = {}
for target in targets:
    model = RandomForestRegressor(n_estimators=100, random_state=42, min_samples_leaf=5)
    model.fit(X, y[target])
    models[target] = model

# Create a future dataframe for the 8th day (2025-09-08) with 15-minute intervals
future_dates = pd.date_range(start='2025-09-08', end='2025-09-09', freq='15T', inclusive='left')
future_df = pd.DataFrame(index=future_dates)
future_df['day_of_year'] = future_df.index.dayofyear
future_df['day_of_month'] = future_df.index.day
future_df['day_of_week'] = future_df.index.dayofweek
future_df['hour'] = future_df.index.hour
future_df['minute'] = future_df.index.minute

future_X = future_df[features]

# Make predictions for the 8th day
predictions = {}
for target, model in models.items():
    predictions[target] = model.predict(future_X)

predictions_df = pd.DataFrame(predictions, index=future_dates)
predictions_df.index.name = 'utc_time'

# Save predictions to a CSV file
predictions_df.to_csv('predictions_8th_day.csv')

# Visualize the predictions vs actuals for x_error on the training data
plt.figure(figsize=(15, 7))
plt.plot(df.index, y['x_error (m)'], label='Actual x_error')
plt.plot(df.index, models['x_error (m)'].predict(X), label='Predicted x_error', linestyle='--')
plt.xlabel('Time')
plt.ylabel('x_error (m)')
plt.title('Actual vs. Predicted x_error on Training Data')
plt.legend()
plt.grid(True)
plt.savefig('x_error_prediction_vs_actual.png')

print("Predictions for the 8th day have been saved to 'predictions_8th_day.csv'")
print("A plot of actual vs. predicted x_error has been saved to 'x_error_prediction_vs_actual.png'")



from scipy.stats import boxcox

# To apply Box-Cox, data must be positive. Find the minimum value in each column
# and add an offset to make all values positive.
offset = predictions_df[targets].min().min()
if offset <= 0:
    offset = abs(offset) + 1
else:
    offset = 0

predictions_df_positive = predictions_df[targets] + offset

# Apply Box-Cox transformation to each target column
transformed_predictions = pd.DataFrame()
for col in targets:
    transformed_data, _ = boxcox(predictions_df_positive[col])
    transformed_predictions[col + '_boxcox'] = transformed_data

# Display the first few rows of the transformed data
display(transformed_predictions.head())

# Create distribution plots for the transformed data
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.flatten()

for i, col in enumerate(targets):
    transformed_col_name = col + '_boxcox'
    axes[i].hist(transformed_predictions[transformed_col_name], bins=30, density=True, alpha=0.7, color='lightgreen')
    axes[i].set_title(f'Distribution of Transformed Predicted {col}')
    axes[i].set_xlabel(transformed_col_name)
    axes[i].set_ylabel('Density')
    # Add a normal distribution curve for comparison
    mu, std = transformed_predictions[transformed_col_name].mean(), transformed_predictions[transformed_col_name].std()
    xmin, xmax = axes[i].get_xlim()
    x = np.linspace(xmin, xmax, 100)
    p = norm.pdf(x, mu, std)
    axes[i].plot(x, p, 'k--', linewidth=2, label=f'Normal Dist.\n(mu={mu:.2f}, std={std:.2f})')
    axes[i].legend()

plt.tight_layout()
plt.show()

# Generate Q-Q plots for the transformed data
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.flatten()

for i, col in enumerate(targets):
    transformed_col_name = col + '_boxcox'
    probplot(transformed_predictions[transformed_col_name], dist="norm", plot=axes[i])
    axes[i].set_title(f'Q-Q Plot for Transformed Predicted {col}')

plt.tight_layout()
plt.show()

# Load the predictions from the CSV file
predictions_df = pd.read_csv('predictions_8th_day.csv')

# Create distribution plots for each error type
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.flatten()

from scipy.stats import norm

for i, col in enumerate(targets):
    axes[i].hist(predictions_df[col], bins=30, density=True, alpha=0.7, color='skyblue')
    axes[i].set_title(f'Distribution of Predicted {col}')
    axes[i].set_xlabel(col)
    axes[i].set_ylabel('Density')
    # Add a normal distribution curve for comparison (optional)
    mu, std = predictions_df[col].mean(), predictions_df[col].std()
    xmin, xmax = axes[i].get_xlim()
    x = np.linspace(xmin, xmax, 100)
    p = norm.pdf(x, mu, std)
    axes[i].plot(x, p, 'k--', linewidth=2, label=f'Normal Dist.\n(mu={mu:.2f}, std={std:.2f})')
    axes[i].legend()

plt.tight_layout()
plt.show()

"""To test how close the distributions are to a normal distribution, we can use statistical tests like the Shapiro-Wilk test or visualize the data using a Q-Q plot. A Q-Q plot compares the quantiles of your data against the quantiles of a theoretical normal distribution. If the data is normally distributed, the points will fall approximately along a straight line.

Let's generate Q-Q plots for each of the error types.
"""

from scipy.stats import probplot, norm

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.flatten()

for i, col in enumerate(targets):
    probplot(predictions_df[col], dist="norm", plot=axes[i])
    axes[i].set_title(f'Q-Q Plot for Predicted {col}')

plt.tight_layout()
plt.show()